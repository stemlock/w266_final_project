{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Base_Model_Colab_v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stemlock/w266_final_project/blob/master/Base_Model_Colab_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cKiLnoGAJWu"
      },
      "source": [
        "This workbook follows the example here: https://huggingface.co/transformers/custom_datasets.html?highlight=sequence#seq-imdb\n",
        "\n",
        "Can download the data directly from Stanford website with the following two commands:\n",
        "wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "tar -xf aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TabsksoQAc_k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a1f0eab-7bf1-49e2-84e3-207b29bde8c5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "CWD = '/content/drive/My Drive/W266 Final Project/Code'\n",
        "\n",
        "%cd $CWD"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/W266 Final Project/Code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTlSloE8FOKl"
      },
      "source": [
        "!pip install transformers==4.12.2\n",
        "!pip install tensorflow==2.5.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TlOLrfYAJWz"
      },
      "source": [
        "# Imports\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from transformers import DistilBertTokenizerFast, TFDistilBertForSequenceClassification, TFTrainer, TFTrainingArguments"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V70skwbn43oA",
        "outputId": "32660578-fbc8-41c6-8b4d-a27b17432a5b"
      },
      "source": [
        "print(\"Tensorflow version:\", tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version: 2.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMFmRBqF47eg"
      },
      "source": [
        "# print(\"Transformers version:\", transformers.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8-9RJ5FAJW1"
      },
      "source": [
        "# Set random seed\n",
        "seed = 42"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7n1eWvPAJW3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "outputId": "7ba51b92-df81-4390-bea6-3b5ecc97d19e"
      },
      "source": [
        "# Read in processed data (Rows with NA in the neutral_review_text had no tokens replaced)\n",
        "df_train = pd.read_csv('data/model_train.csv')\n",
        "df_test = pd.read_csv('data/model_test.csv')\n",
        "df_train.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review_score</th>\n",
              "      <th>review_text</th>\n",
              "      <th>neutral_review_text</th>\n",
              "      <th>neutral_sub_count</th>\n",
              "      <th>female_review_text</th>\n",
              "      <th>female_sub_count</th>\n",
              "      <th>male_review_text</th>\n",
              "      <th>male_sub_count</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6990</td>\n",
              "      <td>1</td>\n",
              "      <td>What the hell is this? Its one of the dumbest ...</td>\n",
              "      <td>what the hell is this? its one of the dumbest ...</td>\n",
              "      <td>1</td>\n",
              "      <td>what the hell is this? its one of the dumbest ...</td>\n",
              "      <td>1</td>\n",
              "      <td>what the hell is this? its one of the dumbest ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12145</td>\n",
              "      <td>1</td>\n",
              "      <td>As you may have gathered from the title, I who...</td>\n",
              "      <td>as you may have gathered from the title, i who...</td>\n",
              "      <td>8</td>\n",
              "      <td>as you may have gathered from the title, i who...</td>\n",
              "      <td>7</td>\n",
              "      <td>as you may have gathered from the title, i who...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7457</td>\n",
              "      <td>1</td>\n",
              "      <td>This Canadian \"movie\" is the worst ever! Stunn...</td>\n",
              "      <td>this canadian \"movie\" is the worst ever! stunn...</td>\n",
              "      <td>7</td>\n",
              "      <td>this canadian \"movie\" is the worst ever! stunn...</td>\n",
              "      <td>5</td>\n",
              "      <td>this canadian \"movie\" is the worst ever! stunn...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7324</td>\n",
              "      <td>1</td>\n",
              "      <td>Being a Film studies graduate I would like to ...</td>\n",
              "      <td>being a film studies graduate i would like to ...</td>\n",
              "      <td>2</td>\n",
              "      <td>being a film studies graduate i would like to ...</td>\n",
              "      <td>1</td>\n",
              "      <td>being a film studies graduate i would like to ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7089</td>\n",
              "      <td>1</td>\n",
              "      <td>A sexually obsessed chef leads a duplicitous l...</td>\n",
              "      <td>a sexually obsessed chef leads a duplicitous l...</td>\n",
              "      <td>7</td>\n",
              "      <td>a sexually obsessed chef leads a duplicitous l...</td>\n",
              "      <td>4</td>\n",
              "      <td>a sexually obsessed chef leads a duplicitous l...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   review_id  review_score  ... male_sub_count label\n",
              "0       6990             1  ...              0     0\n",
              "1      12145             1  ...              1     0\n",
              "2       7457             1  ...              2     0\n",
              "3       7324             1  ...              1     0\n",
              "4       7089             1  ...              3     0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV2kQwfshkCu"
      },
      "source": [
        "# Extract the male vs female majority texts\n",
        "df_female_majority = df_test[df_test['male_sub_count'] > df_test['female_sub_count']]\n",
        "df_male_majority = df_test[df_test['male_sub_count'] < df_test['female_sub_count']]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnLOai5MiFGK",
        "outputId": "4b5d5467-17a3-40e8-ea6d-0974d1d6c625"
      },
      "source": [
        "# Average sentiment for female majority texts\n",
        "print(\"Average female review binary sentiment:\", df_female_majority['label'].mean())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average female review binary sentiment: 0.4896039603960396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VevUcJ8njWby",
        "outputId": "51dc1780-745a-4914-afe8-671ebd5e1028"
      },
      "source": [
        "# Average review score for female majority texts\n",
        "print(\"Average female review score 1-10:\", df_female_majority['review_score'].mean())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average female review score 1-10: 5.436138613861386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtS6FogMiSiI",
        "outputId": "a2616331-5815-4af4-c2eb-34258481d918"
      },
      "source": [
        "# Average sentiment for male majority texts\n",
        "print(\"Average male review binary sentiment:\", df_male_majority['label'].mean())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average male review binary sentiment: 0.5035229420862691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLXTizgqjnni",
        "outputId": "99b1b62d-ba37-4c98-ce54-458d697641e0"
      },
      "source": [
        "# Average review score for male majority texts\n",
        "print(\"Average male review score 1-10:\", df_male_majority['review_score'].mean())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average male review score 1-10: 5.509709572091425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTrnQ2GbkTTc",
        "outputId": "21225d35-1fcc-4dc0-945e-6331e9c4ba30"
      },
      "source": [
        "# Distribution of scores across review scores for female majority texts\n",
        "df_female_majority['review_score'].value_counts()/len(df_female_majority)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     0.181683\n",
              "10    0.171782\n",
              "8     0.121287\n",
              "4     0.121287\n",
              "3     0.111386\n",
              "7     0.106931\n",
              "2     0.096040\n",
              "9     0.089604\n",
              "Name: review_score, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vM8jKJ2kKHc",
        "outputId": "1aa31f30-79a0-499d-8c51-ef6d0ef9f5c9"
      },
      "source": [
        "# Distribution of scores across review scores for male majority texts\n",
        "df_male_majority['review_score'].value_counts()/len(df_male_majority)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     0.197457\n",
              "10    0.190067\n",
              "8     0.120124\n",
              "4     0.105860\n",
              "3     0.101564\n",
              "7     0.100361\n",
              "9     0.092971\n",
              "2     0.091596\n",
              "Name: review_score, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMdjzwMInAT3"
      },
      "source": [
        "# Extract the proportion of male vs female tokens per review\n",
        "male_proportion = (df_test['female_sub_count']/df_test['neutral_sub_count'])\n",
        "female_proportion = (df_test['male_sub_count']/df_test['neutral_sub_count'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KWiEVdrnFJ_",
        "outputId": "0b08df47-e991-4b2f-e585-8663f093c09e"
      },
      "source": [
        "# Weighted average sentiment for female tokens\n",
        "(df_test['label']*female_proportion).sum()/female_proportion.sum()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4922782109404571"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZUcV1WGnJQO",
        "outputId": "a41776c3-89a1-42dc-b8ca-76de7526d9ef"
      },
      "source": [
        "# Weighted average review scores for female tokens\n",
        "(df_test['review_score']*female_proportion).sum()/female_proportion.sum()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.440864712868192"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHD9eRnCoNwx",
        "outputId": "63cd6ff5-f256-4803-935b-791e704f74e1"
      },
      "source": [
        "# Weighted average sentiment for male tokens\n",
        "(df_test['label']*male_proportion).sum()/male_proportion.sum()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5028605798629667"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NSn2Y88kkP7",
        "outputId": "5a8737b1-4402-407e-9dab-8ce7ed737ca3"
      },
      "source": [
        "# Weighted average review scores for male tokens\n",
        "(df_test['review_score']*male_proportion).sum()/male_proportion.sum()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.508159425039407"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I9lXGmQyN4T"
      },
      "source": [
        "# ## TO DO: Try to fix this function. For some reason, this causes the model.fit() to fail\n",
        "# def encode_datasets(X_train, y_train, X_test, y_test, tokenizer, split_size=0.5, seed=42):\n",
        "\n",
        "#   '''\n",
        "#   Takes in train and test data and encodes them into train, dev, and test\n",
        "#   TF datasets using the provided tokenizer.\n",
        "#   '''\n",
        "\n",
        "#   # Split test set into dev and test\n",
        "#   X_dev, X_test, y_dev, y_test = train_test_split(X_test, y_test, test_size=split_size, random_state=seed)\n",
        "\n",
        "#   # Apply tokenizer to each dataset\n",
        "#   train_encodings = tokenizer(X_train, truncation=True, padding=True)\n",
        "#   dev_encodings = tokenizer(X_dev, truncation=True, padding=True)\n",
        "#   test_encodings = tokenizer(X_test, truncation=True, padding=True)\n",
        "\n",
        "#   # Turn encodings into datasets for easy batching\n",
        "#   train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#       dict(train_encodings),\n",
        "#       y_train\n",
        "#   ))\n",
        "#   dev_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#       dict(dev_encodings),\n",
        "#       y_dev\n",
        "#   ))\n",
        "#   test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#       dict(test_encodings),\n",
        "#       y_test\n",
        "#   ))\n",
        "\n",
        "#   return train_dataset, dev_dataset, test_dataset"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU9Qx8R5-NjG"
      },
      "source": [
        "# # Load data\n",
        "# train_texts = df_train['review_text'].values.tolist()\n",
        "# n_train_texts = df_train['neutral_review_text'].values.tolist()\n",
        "# f_train_texts = df_train['female_review_text'].values.tolist()\n",
        "# m_train_texts = df_train['male_review_text'].values.tolist()\n",
        "# train_labels = df_train['label'].values.tolist()\n",
        "\n",
        "# test_texts = df_test['review_text'].values.tolist()\n",
        "# n_test_texts = df_test['neutral_review_text'].values.tolist()\n",
        "# f_test_texts = df_test['female_review_text'].values.tolist()\n",
        "# m_test_texts = df_test['male_review_text'].values.tolist()\n",
        "# test_labels = df_test['label'].values.tolist()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHS5FQKcz2Th"
      },
      "source": [
        "# # Specify tokenizer and encode each dataset\n",
        "# tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# train_dataset, dev_dataset, test_dataset = encode_datasets(train_texts, train_labels, \n",
        "#                                                            test_texts, test_labels,\n",
        "#                                                            tokenizer)\n",
        "# n_train_dataset, n_dev_dataset, n_test_dataset = encode_datasets(n_train_texts, train_labels, \n",
        "#                                                                  n_test_texts, test_labels,\n",
        "#                                                                  tokenizer)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8i696DrAJW7"
      },
      "source": [
        "# Load data\n",
        "train_texts = df_train['review_text'].values.tolist()\n",
        "n_train_texts = df_train['neutral_review_text'].values.tolist()\n",
        "f_train_texts = df_train['female_review_text'].values.tolist()\n",
        "m_train_texts = df_train['male_review_text'].values.tolist()\n",
        "train_labels = df_train['label'].values.tolist()\n",
        "\n",
        "test_texts = df_test['review_text'].values.tolist()\n",
        "n_test_texts = df_test['neutral_review_text'].values.tolist()\n",
        "f_test_texts = df_test['female_review_text'].values.tolist()\n",
        "m_test_texts = df_test['male_review_text'].values.tolist()\n",
        "test_labels = df_test['label'].values.tolist()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dt-BL3PBAJW8"
      },
      "source": [
        "# Create dev set from portion of test set using split\n",
        "dev_texts, test_texts, _, _ = train_test_split(test_texts, test_labels, test_size=.5, random_state=seed)\n",
        "n_dev_texts, n_test_texts, _, _ = train_test_split(n_test_texts, test_labels, test_size=.5, random_state=seed)\n",
        "f_dev_texts, f_test_texts, _, _ = train_test_split(f_test_texts, test_labels, test_size=.5, random_state=seed)\n",
        "m_dev_texts, m_test_texts, dev_labels, test_labels = train_test_split(m_test_texts, test_labels, \n",
        "                                                                        test_size=.5, random_state=seed)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQwDIzF2SOLK"
      },
      "source": [
        "###############\n",
        "--------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhPCDyapOfdO"
      },
      "source": [
        "# TEST SMALL DATASETS\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "small_train_encodings = tokenizer(train_texts[:1000], max_length=50, truncation=True, padding=True, return_tensors='tf')\n",
        "small_dev_encodings = tokenizer(dev_texts[:1000], max_length=50, truncation=True, padding=True, return_tensors='tf')\n",
        "small_test_encodings = tokenizer(test_texts[:1000], max_length=50, truncation=True, padding=True, return_tensors='tf')\n",
        "\n",
        "small_train_labels = tf.convert_to_tensor(train_labels[:1000])\n",
        "small_dev_labels = tf.convert_to_tensor(dev_labels[:1000])\n",
        "small_test_labels = tf.convert_to_tensor(test_labels[:1000])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deae2Cy-OA_c"
      },
      "source": [
        "# TEST SMALL DATASETS\n",
        "small_train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(small_train_encodings),\n",
        "    small_train_labels\n",
        ")).shuffle(1000, seed=seed).batch(8)\n",
        "\n",
        "small_dev_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(small_dev_encodings),\n",
        "    small_dev_labels\n",
        ")).batch(8)\n",
        "\n",
        "small_test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(small_test_encodings),\n",
        "    small_test_labels\n",
        ")).batch(8)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrYkXYvVRLaZ",
        "outputId": "b86ce432-49ea-4bad-bfa4-9a1b8c310c91"
      },
      "source": [
        "# Initialize the TPU devices\n",
        "if os.environ['COLAB_TPU_ADDR']:\n",
        "  cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "  tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "  tpu_strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "  print('Using TPU')\n",
        "elif tf.config.list_physical_devices('GPU'):\n",
        "  strategy = tf.distribute.MirroredStrategy()\n",
        "  print('Using GPU')\n",
        "else:\n",
        "  raise ValueError('Running on CPU is not recommended.')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.50.132.42:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.50.132.42:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.50.132.42:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.50.132.42:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfR3rAGFPlk8",
        "outputId": "ffd5d34f-530b-491a-efef-7fa0b3121cb0"
      },
      "source": [
        "with tpu_strategy.scope():\n",
        "  small_model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
        "  small_model.compile(\n",
        "      optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      metrics=tf.metrics.SparseCategoricalAccuracy('accuracy'),\n",
        "      ) \n",
        "  small_model.fit(small_dev_dataset, validation_data=small_test_dataset, epochs=3)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_layer_norm', 'activation_13', 'vocab_projector', 'vocab_transform']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_59']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 50) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 50) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 50) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 50) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 [==============================] - ETA: 0s - loss: 0.6299 - accuracy: 0.6220"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 50) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 50) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 [==============================] - 64s 100ms/step - loss: 0.6299 - accuracy: 0.6220 - val_loss: 0.5737 - val_accuracy: 0.6910\n",
            "Epoch 2/3\n",
            "125/125 [==============================] - 7s 55ms/step - loss: 0.4014 - accuracy: 0.8300 - val_loss: 0.5639 - val_accuracy: 0.7190\n",
            "Epoch 3/3\n",
            "125/125 [==============================] - 7s 58ms/step - loss: 0.2554 - accuracy: 0.9070 - val_loss: 0.6876 - val_accuracy: 0.7170\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjKkeRSeRlnU"
      },
      "source": [
        "################"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnRvIbPMKFQ4"
      },
      "source": [
        "# Change labels list into tf.Tensors\n",
        "tf_train_labels = tf.convert_to_tensor(train_labels)\n",
        "tf_dev_labels = tf.convert_to_tensor(dev_labels)\n",
        "tf_test_labels = tf.convert_to_tensor(test_labels)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VVafMpfAJW8"
      },
      "source": [
        "# Specify tokenizer and batch encode original datasets\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, return_tensors='tf')\n",
        "dev_encodings = tokenizer(dev_texts, truncation=True, padding=True, return_tensors='tf')\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True, return_tensors='tf')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXYKPoMoAJW8"
      },
      "source": [
        "# Turn original encodings into datasets for easy batching\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_encodings),\n",
        "    tf_train_labels\n",
        ")).shuffle(10000, seed=seed).batch(16)\n",
        "\n",
        "dev_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(dev_encodings),\n",
        "    tf_dev_labels\n",
        ")).batch(16)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(test_encodings),\n",
        "    tf_test_labels\n",
        ")).batch(16)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgfwqs5i89wy"
      },
      "source": [
        "# Batch encode the neutral datasets\n",
        "n_train_encodings = tokenizer(n_train_texts, truncation=True, padding=True, return_tensors='tf')\n",
        "n_dev_encodings = tokenizer(n_dev_texts, truncation=True, padding=True, return_tensors='tf')\n",
        "n_test_encodings = tokenizer(n_test_texts, truncation=True, padding=True, return_tensors='tf')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ois9IdKx9MtH"
      },
      "source": [
        "# Turn neutral encodings into datasets for easy batching\n",
        "n_train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(n_train_encodings),\n",
        "    tf_train_labels\n",
        ")).shuffle(10000, seed=seed).batch(16)\n",
        "\n",
        "n_dev_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(n_dev_encodings),\n",
        "    tf_dev_labels\n",
        ")).batch(16)\n",
        "\n",
        "n_test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(n_test_encodings),\n",
        "    tf_test_labels\n",
        ")).batch(16)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B28YHNWE7lPJ"
      },
      "source": [
        "# Starter function to create the model (we can improve on this when we start using more complex models)\n",
        "def create_model():\n",
        "\n",
        "  return TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbOfz02TYJJk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5db02f9-a43b-45c1-b59e-f73b540f249e"
      },
      "source": [
        "# Initialize the TPU devices\n",
        "if os.environ['COLAB_TPU_ADDR']:\n",
        "  cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "  tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "  tpu_strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "  print('Using TPU')\n",
        "elif tf.config.list_physical_devices('GPU'):\n",
        "  strategy = tf.distribute.MirroredStrategy()\n",
        "  print('Using GPU')\n",
        "else:\n",
        "  raise ValueError('Running on CPU is not recommended.')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.50.132.42:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.50.132.42:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.50.132.42:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.50.132.42:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip8Ox5RiAjKn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c40ce700-5780-4f1e-f6b4-f2c581e85566"
      },
      "source": [
        "# Create the model within each device scope\n",
        "models = []\n",
        "histories = []\n",
        "for train, dev in [(train_dataset, dev_dataset), (n_train_dataset, dev_dataset)]:\n",
        "  with tpu_strategy.scope():\n",
        "    model = create_model()\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
        "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n",
        "    \n",
        "  print(model.summary())\n",
        "\n",
        "  history = model.fit(train, validation_data=dev, epochs=5)\n",
        "    \n",
        "  histories.append(history)\n",
        "  models.append(model)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_layer_norm', 'activation_13', 'vocab_projector', 'vocab_transform']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_79']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_distil_bert_for_sequence_classification_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "distilbert (TFDistilBertMain multiple                  66362880  \n",
            "_________________________________________________________________\n",
            "pre_classifier (Dense)       multiple                  590592    \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  1538      \n",
            "_________________________________________________________________\n",
            "dropout_79 (Dropout)         multiple                  0         \n",
            "=================================================================\n",
            "Total params: 66,955,010\n",
            "Trainable params: 66,955,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2092/2092 [==============================] - ETA: 0s - loss: 0.3488 - accuracy: 0.8395"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2092/2092 [==============================] - 194s 69ms/step - loss: 0.3488 - accuracy: 0.8395 - val_loss: 0.7158 - val_accuracy: 0.6782\n",
            "Epoch 2/5\n",
            "2092/2092 [==============================] - 136s 65ms/step - loss: 0.2790 - accuracy: 0.8855 - val_loss: 0.6375 - val_accuracy: 0.6777\n",
            "Epoch 3/5\n",
            "2092/2092 [==============================] - 136s 65ms/step - loss: 0.2118 - accuracy: 0.9188 - val_loss: 0.4266 - val_accuracy: 0.8310\n",
            "Epoch 4/5\n",
            "2092/2092 [==============================] - 137s 65ms/step - loss: 0.1508 - accuracy: 0.9444 - val_loss: 0.3304 - val_accuracy: 0.8762\n",
            "Epoch 5/5\n",
            "2092/2092 [==============================] - 136s 65ms/step - loss: 0.1157 - accuracy: 0.9591 - val_loss: 0.3163 - val_accuracy: 0.8833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_layer_norm', 'activation_13', 'vocab_projector', 'vocab_transform']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_99']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_distil_bert_for_sequence_classification_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "distilbert (TFDistilBertMain multiple                  66362880  \n",
            "_________________________________________________________________\n",
            "pre_classifier (Dense)       multiple                  590592    \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  1538      \n",
            "_________________________________________________________________\n",
            "dropout_99 (Dropout)         multiple                  0         \n",
            "=================================================================\n",
            "Total params: 66,955,010\n",
            "Trainable params: 66,955,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2092/2092 [==============================] - ETA: 0s - loss: 0.2908 - accuracy: 0.8774"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2092/2092 [==============================] - 194s 68ms/step - loss: 0.2908 - accuracy: 0.8774 - val_loss: 0.4552 - val_accuracy: 0.8274\n",
            "Epoch 2/5\n",
            "2092/2092 [==============================] - 136s 65ms/step - loss: 0.2270 - accuracy: 0.9061 - val_loss: 0.4813 - val_accuracy: 0.8064\n",
            "Epoch 3/5\n",
            "2092/2092 [==============================] - 136s 65ms/step - loss: 0.1763 - accuracy: 0.9341 - val_loss: 0.3603 - val_accuracy: 0.8671\n",
            "Epoch 4/5\n",
            "2092/2092 [==============================] - 136s 65ms/step - loss: 0.1358 - accuracy: 0.9516 - val_loss: 0.3270 - val_accuracy: 0.8709\n",
            "Epoch 5/5\n",
            "2092/2092 [==============================] - 136s 65ms/step - loss: 0.1457 - accuracy: 0.9463 - val_loss: 0.4031 - val_accuracy: 0.8678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_7r-d2uV23L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9ea3807-d8df-4389-af1f-49c792f4f77e"
      },
      "source": [
        "# Evaluate the original baseline model\n",
        "models[0].evaluate(x=test_dataset)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 7s 24ms/step - loss: 0.3141 - accuracy: 0.8793\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.31414440274238586, 0.8792732954025269]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOVB2K-dV5Rc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39c8e629-a225-49a6-f63d-cf0b66900935"
      },
      "source": [
        "# Evaluate the UNK baseline model\n",
        "models[1].evaluate(x=test_dataset)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 7s 24ms/step - loss: 0.3795 - accuracy: 0.8716\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.37952134013175964, 0.8716232776641846]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46jT-IlMAJW9"
      },
      "source": [
        "# Save the models\n",
        "models[0].save_pretrained(CWD + \"/models/original_base_model_v1\")\n",
        "models[1].save_pretrained(CWD + \"/models/UNK_base_model_v1\")"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnUxrlUbYj4y"
      },
      "source": [
        "# Batch encode the male and female datasets\n",
        "m_train_encodings = tokenizer(m_train_texts, truncation=True, padding=True, return_tensors='tf')\n",
        "m_dev_encodings = tokenizer(m_dev_texts, truncation=True, padding=True, return_tensors='tf')\n",
        "m_test_encodings = tokenizer(m_test_texts, truncation=True, padding=True, return_tensors='tf')\n",
        "f_train_encodings = tokenizer(f_train_texts, truncation=True, padding=True, return_tensors='tf')\n",
        "f_dev_encodings = tokenizer(f_dev_texts, truncation=True, padding=True, return_tensors='tf')\n",
        "f_test_encodings = tokenizer(f_test_texts, truncation=True, padding=True, return_tensors='tf')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSa25jXQYj4y"
      },
      "source": [
        "# Turn male and female encodings into datasets for easy batching\n",
        "\n",
        "# m_train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#     dict(m_train_encodings),\n",
        "#     tf_train_labels\n",
        "# )).shuffle(10000, seed=seed).batch(16)\n",
        "\n",
        "m_dev_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(m_dev_encodings),\n",
        "    tf_dev_labels\n",
        ")).batch(16)\n",
        "\n",
        "m_test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(m_test_encodings),\n",
        "    tf_test_labels\n",
        ")).batch(16)\n",
        "\n",
        "# f_train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#     dict(f_train_encodings),\n",
        "#     tf_train_labels\n",
        "# )).shuffle(10000, seed=seed).batch(16)\n",
        "\n",
        "f_dev_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(f_dev_encodings),\n",
        "    tf_dev_labels\n",
        ")).batch(16)\n",
        "\n",
        "f_test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(f_test_encodings),\n",
        "    tf_test_labels\n",
        ")).batch(16)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLD8-4jTpcjY",
        "outputId": "68e372e7-fdb7-44bd-c92d-3760435d55c8"
      },
      "source": [
        "# Get the logits for both models on the male and female datasets respectively\n",
        "orig_m_logit_preds = models[0].predict(x=m_test_dataset).logits\n",
        "orig_f_logit_preds = models[0].predict(x=f_test_dataset).logits\n",
        "unk_m_logit_preds = models[1].predict(x=m_test_dataset).logits\n",
        "unk_f_logit_preds = models[1].predict(x=f_test_dataset).logits"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkrM8JRGvIOI",
        "outputId": "dd3b26b4-2f21-45af-ba25-91cb529bbd03"
      },
      "source": [
        "# Get the average sentiments for the original model\n",
        "m_pred_probs = tf.math.softmax(orig_m_logit_preds, axis=-1)\n",
        "f_pred_probs = tf.math.softmax(orig_f_logit_preds, axis=-1)\n",
        "\n",
        "print(\"Average Male Positive Sentiment:\", np.mean(m_pred_probs[:,1]))\n",
        "print(\"Average Female Positive Sentiment:\", np.mean(f_pred_probs[:,1]))\n",
        "print(\"Difference in Sentiment (Male - Female):\", np.mean(m_pred_probs[:,1])-np.mean(f_pred_probs[:,1]))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Male Positive Sentiment: 0.55594724\n",
            "Average Female Positive Sentiment: 0.5429732\n",
            "Difference in Sentiment (Male - Female): 0.012974024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk34chhgbC3B",
        "outputId": "04c6cf47-4ec9-415b-f8f2-5f1506ce1743"
      },
      "source": [
        "# Get the average sentiments for the unknown model\n",
        "m_pred_probs = tf.math.softmax(unk_m_logit_preds, axis=-1)\n",
        "f_pred_probs = tf.math.softmax(unk_f_logit_preds, axis=-1)\n",
        "\n",
        "print(\"Average Male Positive Sentiment:\", np.mean(m_pred_probs[:,1]))\n",
        "print(\"Average Female Positive Sentiment:\", np.mean(f_pred_probs[:,1]))\n",
        "print(\"Difference in Sentiment (Male - Female):\", np.mean(m_pred_probs[:,1])-np.mean(f_pred_probs[:,1]))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Male Positive Sentiment: 0.592404\n",
            "Average Female Positive Sentiment: 0.598442\n",
            "Difference in Sentiment (Male - Female): -0.00603801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORLHTMn_wC0S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}