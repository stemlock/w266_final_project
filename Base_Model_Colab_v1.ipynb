{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Base_Model_Colab_v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stemlock/w266_final_project/blob/master/Base_Model_Colab_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C19pmdcHn3v"
      },
      "source": [
        "## Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TabsksoQAc_k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31f958e6-2e22-41cb-d7fd-f1abc32be748"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "CWD = '/content/drive/My Drive/W266 Final Project/Code'\n",
        "\n",
        "%cd $CWD"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/W266 Final Project/Code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTlSloE8FOKl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd34d9e1-ff29-41c6-fc81-ba25adbb8d8d"
      },
      "source": [
        "!pip install transformers==4.12.2\n",
        "!pip install tensorflow==2.5.2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.12.2\n",
            "  Downloading transformers-4.12.2-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.2) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.2) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.2) (2019.12.20)\n",
            "Collecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.2.0-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 380 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.2) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 42.0 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 57.3 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 24.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.2) (4.8.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.2) (4.62.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.2) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers==4.12.2) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.12.2) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.12.2) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.12.2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.12.2) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.12.2) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.12.2) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.12.2) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.12.2) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.12.2) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.2.0 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.2\n",
            "Collecting tensorflow==2.5.2\n",
            "  Downloading tensorflow-2.5.2-cp37-cp37m-manylinux2010_x86_64.whl (454.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 454.4 MB 23 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.2) (1.15.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.2) (1.19.5)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting keras-nightly~=2.5.0.dev\n",
            "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 41.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.2) (3.17.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.2) (0.2.0)\n",
            "Collecting tensorflow-estimator<2.6.0,>=2.5.0\n",
            "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 24.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.2) (3.1.0)\n",
            "Collecting grpcio~=1.34.0\n",
            "  Downloading grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 49.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.2) (2.7.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.2) (1.6.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.2) (0.37.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.2) (3.3.0)\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.2) (0.12.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.2) (1.1.2)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.2) (1.1.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.2) (0.4.0)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow==2.5.2) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.2) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.2) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.2) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.2) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.2) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.2) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.2) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.2) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.2) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.2) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.2) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.2) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.2) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.2) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.2) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.2) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.2) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.2) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.2) (3.1.1)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68719 sha256=da437e55de7b9ed77efa9d860c437566a6368e57716542ee86fbe3e90984db6f\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built wrapt\n",
            "Installing collected packages: typing-extensions, grpcio, wrapt, tensorflow-estimator, keras-nightly, flatbuffers, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.10.0.2\n",
            "    Uninstalling typing-extensions-3.10.0.2:\n",
            "      Successfully uninstalled typing-extensions-3.10.0.2\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.42.0\n",
            "    Uninstalling grpcio-1.42.0:\n",
            "      Successfully uninstalled grpcio-1.42.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.13.3\n",
            "    Uninstalling wrapt-1.13.3:\n",
            "      Successfully uninstalled wrapt-1.13.3\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "Successfully installed flatbuffers-1.12 grpcio-1.34.1 keras-nightly-2.5.0.dev2021032900 tensorflow-2.5.2 tensorflow-estimator-2.5.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TlOLrfYAJWz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "e7565759-6164-4601-8c8a-51122ce95bb1"
      },
      "source": [
        "# Imports\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from transformers import DistilBertTokenizerFast, TFDistilBertForSequenceClassification, TFTrainer, TFTrainingArguments"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-f3ca32a80221>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDistilBertTokenizerFast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTFDistilBertForSequenceClassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTFTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTFTrainingArguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m from .file_utils import (\n\u001b[1;32m     45\u001b[0m     \u001b[0m_LazyModule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/dependency_versions_check.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tokenizers\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m# must be loaded here, or else tqdm check may fail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfile_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_tokenizers_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tokenizers_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfilelock\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileLock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHfApi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHfFolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRepository\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimportlib_metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/huggingface_hub/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mwhoami\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m )\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhub_mixin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelHubMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPyTorchModelHubMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minference_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInferenceApi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m from .keras_mixin import (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;31m# Appease the type checker; ordinarily this binding is inserted by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: KeyboardInterrupt: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V70skwbn43oA",
        "outputId": "e37a43ff-f026-4b26-accc-329c6698e90b"
      },
      "source": [
        "print(\"Tensorflow version:\", tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version: 2.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMFmRBqF47eg"
      },
      "source": [
        "# print(\"Transformers version:\", transformers.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8-9RJ5FAJW1"
      },
      "source": [
        "# Set random seed\n",
        "seed = 42"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Frg-v4SIHtik"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7n1eWvPAJW3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "55e65001-1867-465e-81f1-9395f3bf3fd4"
      },
      "source": [
        "# Read in processed data (Rows with NA in the neutral_review_text had no tokens replaced)\n",
        "df_train = pd.read_csv('data/model_train.csv')\n",
        "df_test = pd.read_csv('data/model_test.csv')\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review_score</th>\n",
              "      <th>review_text</th>\n",
              "      <th>neutral_review_text</th>\n",
              "      <th>neutral_sub_count</th>\n",
              "      <th>female_review_text</th>\n",
              "      <th>female_sub_count</th>\n",
              "      <th>male_review_text</th>\n",
              "      <th>male_sub_count</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6990</td>\n",
              "      <td>1</td>\n",
              "      <td>What the hell is this? Its one of the dumbest ...</td>\n",
              "      <td>what the hell is this? its one of the dumbest ...</td>\n",
              "      <td>1</td>\n",
              "      <td>what the hell is this? its one of the dumbest ...</td>\n",
              "      <td>1</td>\n",
              "      <td>what the hell is this? its one of the dumbest ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12145</td>\n",
              "      <td>1</td>\n",
              "      <td>As you may have gathered from the title, I who...</td>\n",
              "      <td>as you may have gathered from the title, i who...</td>\n",
              "      <td>8</td>\n",
              "      <td>as you may have gathered from the title, i who...</td>\n",
              "      <td>7</td>\n",
              "      <td>as you may have gathered from the title, i who...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7457</td>\n",
              "      <td>1</td>\n",
              "      <td>This Canadian \"movie\" is the worst ever! Stunn...</td>\n",
              "      <td>this canadian \"movie\" is the worst ever! stunn...</td>\n",
              "      <td>7</td>\n",
              "      <td>this canadian \"movie\" is the worst ever! stunn...</td>\n",
              "      <td>5</td>\n",
              "      <td>this canadian \"movie\" is the worst ever! stunn...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7324</td>\n",
              "      <td>1</td>\n",
              "      <td>Being a Film studies graduate I would like to ...</td>\n",
              "      <td>being a film studies graduate i would like to ...</td>\n",
              "      <td>2</td>\n",
              "      <td>being a film studies graduate i would like to ...</td>\n",
              "      <td>1</td>\n",
              "      <td>being a film studies graduate i would like to ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7089</td>\n",
              "      <td>1</td>\n",
              "      <td>A sexually obsessed chef leads a duplicitous l...</td>\n",
              "      <td>a sexually obsessed chef leads a duplicitous l...</td>\n",
              "      <td>7</td>\n",
              "      <td>a sexually obsessed chef leads a duplicitous l...</td>\n",
              "      <td>4</td>\n",
              "      <td>a sexually obsessed chef leads a duplicitous l...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   review_id  review_score  ... male_sub_count label\n",
              "0       6990             1  ...              0     0\n",
              "1      12145             1  ...              1     0\n",
              "2       7457             1  ...              2     0\n",
              "3       7324             1  ...              1     0\n",
              "4       7089             1  ...              3     0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjJKICtbHyaG"
      },
      "source": [
        "## Baseline Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kzs4ALv_H6aw"
      },
      "source": [
        "### Majority tokens average"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV2kQwfshkCu"
      },
      "source": [
        "# Extract the male vs female majority texts\n",
        "df_female_majority = df_test[df_test['male_sub_count'] > df_test['female_sub_count']]\n",
        "df_male_majority = df_test[df_test['male_sub_count'] < df_test['female_sub_count']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnLOai5MiFGK",
        "outputId": "23ef32d3-360b-40e0-8980-4365300a36b7"
      },
      "source": [
        "# Average sentiment for female majority texts\n",
        "print(\"Average female review binary sentiment:\", df_female_majority['label'].mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average female review binary sentiment: 0.4896039603960396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VevUcJ8njWby",
        "outputId": "0918e050-143a-45f8-d5be-1199db2b66d6"
      },
      "source": [
        "# Average review score for female majority texts\n",
        "print(\"Average female review score 1-10:\", df_female_majority['review_score'].mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average female review score 1-10: 5.436138613861386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtS6FogMiSiI",
        "outputId": "d6f8b8be-19d7-4448-a128-6646cf4659a2"
      },
      "source": [
        "# Average sentiment for male majority texts\n",
        "print(\"Average male review binary sentiment:\", df_male_majority['label'].mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average male review binary sentiment: 0.5035229420862691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLXTizgqjnni",
        "outputId": "9ccd36b2-63fc-4171-ec8c-1f201f2aa0f5"
      },
      "source": [
        "# Average review score for male majority texts\n",
        "print(\"Average male review score 1-10:\", df_male_majority['review_score'].mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average male review score 1-10: 5.509709572091425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTrnQ2GbkTTc",
        "outputId": "0e24b99a-b2f9-4c60-8ecd-cc2d85009722"
      },
      "source": [
        "# Distribution of scores across review scores for female majority texts\n",
        "df_female_majority['review_score'].value_counts()/len(df_female_majority)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     0.181683\n",
              "10    0.171782\n",
              "8     0.121287\n",
              "4     0.121287\n",
              "3     0.111386\n",
              "7     0.106931\n",
              "2     0.096040\n",
              "9     0.089604\n",
              "Name: review_score, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vM8jKJ2kKHc",
        "outputId": "23a8e364-1f93-4448-f687-cb1d57dc8e93"
      },
      "source": [
        "# Distribution of scores across review scores for male majority texts\n",
        "df_male_majority['review_score'].value_counts()/len(df_male_majority)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     0.197457\n",
              "10    0.190067\n",
              "8     0.120124\n",
              "4     0.105860\n",
              "3     0.101564\n",
              "7     0.100361\n",
              "9     0.092971\n",
              "2     0.091596\n",
              "Name: review_score, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmzVoXGVIATU"
      },
      "source": [
        "### Proportional weighted average"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMdjzwMInAT3"
      },
      "source": [
        "# Extract the proportion of male vs female tokens per review\n",
        "male_proportion = (df_test['female_sub_count']/df_test['neutral_sub_count'])\n",
        "female_proportion = (df_test['male_sub_count']/df_test['neutral_sub_count'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KWiEVdrnFJ_",
        "outputId": "0b08df47-e991-4b2f-e585-8663f093c09e"
      },
      "source": [
        "# Weighted average sentiment for female tokens\n",
        "(df_test['label']*female_proportion).sum()/female_proportion.sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4922782109404571"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZUcV1WGnJQO",
        "outputId": "a41776c3-89a1-42dc-b8ca-76de7526d9ef"
      },
      "source": [
        "# Weighted average review scores for female tokens\n",
        "(df_test['review_score']*female_proportion).sum()/female_proportion.sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.440864712868192"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHD9eRnCoNwx",
        "outputId": "63cd6ff5-f256-4803-935b-791e704f74e1"
      },
      "source": [
        "# Weighted average sentiment for male tokens\n",
        "(df_test['label']*male_proportion).sum()/male_proportion.sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5028605798629667"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NSn2Y88kkP7",
        "outputId": "5a8737b1-4402-407e-9dab-8ce7ed737ca3"
      },
      "source": [
        "# Weighted average review scores for male tokens\n",
        "(df_test['review_score']*male_proportion).sum()/male_proportion.sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.508159425039407"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4swCd7jIESR"
      },
      "source": [
        "## Data Transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I9lXGmQyN4T"
      },
      "source": [
        "# ## TO DO: Try to fix this function. For some reason, this causes the model.fit() to fail\n",
        "# def encode_datasets(X_train, y_train, X_test, y_test, tokenizer, split_size=0.5, seed=42):\n",
        "\n",
        "#   '''\n",
        "#   Takes in train and test data and encodes them into train, dev, and test\n",
        "#   TF datasets using the provided tokenizer.\n",
        "#   '''\n",
        "\n",
        "#   # Split test set into dev and test\n",
        "#   X_dev, X_test, y_dev, y_test = train_test_split(X_test, y_test, test_size=split_size, random_state=seed)\n",
        "\n",
        "#   # Apply tokenizer to each dataset\n",
        "#   train_encodings = tokenizer(X_train, truncation=True, padding=True)\n",
        "#   dev_encodings = tokenizer(X_dev, truncation=True, padding=True)\n",
        "#   test_encodings = tokenizer(X_test, truncation=True, padding=True)\n",
        "\n",
        "#   # Turn encodings into datasets for easy batching\n",
        "#   train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#       dict(train_encodings),\n",
        "#       y_train\n",
        "#   ))\n",
        "#   dev_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#       dict(dev_encodings),\n",
        "#       y_dev\n",
        "#   ))\n",
        "#   test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#       dict(test_encodings),\n",
        "#       y_test\n",
        "#   ))\n",
        "\n",
        "#   return train_dataset, dev_dataset, test_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU9Qx8R5-NjG"
      },
      "source": [
        "# # Load data\n",
        "# train_texts = df_train['review_text'].values.tolist()\n",
        "# n_train_texts = df_train['neutral_review_text'].values.tolist()\n",
        "# f_train_texts = df_train['female_review_text'].values.tolist()\n",
        "# m_train_texts = df_train['male_review_text'].values.tolist()\n",
        "# train_labels = df_train['label'].values.tolist()\n",
        "\n",
        "# test_texts = df_test['review_text'].values.tolist()\n",
        "# n_test_texts = df_test['neutral_review_text'].values.tolist()\n",
        "# f_test_texts = df_test['female_review_text'].values.tolist()\n",
        "# m_test_texts = df_test['male_review_text'].values.tolist()\n",
        "# test_labels = df_test['label'].values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHS5FQKcz2Th"
      },
      "source": [
        "# # Specify tokenizer and encode each dataset\n",
        "# tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# train_dataset, dev_dataset, test_dataset = encode_datasets(train_texts, train_labels, \n",
        "#                                                            test_texts, test_labels,\n",
        "#                                                            tokenizer)\n",
        "# n_train_dataset, n_dev_dataset, n_test_dataset = encode_datasets(n_train_texts, train_labels, \n",
        "#                                                                  n_test_texts, test_labels,\n",
        "#                                                                  tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nR2fsZXK3m7"
      },
      "source": [
        "### Split data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8i696DrAJW7"
      },
      "source": [
        "# Load data\n",
        "train_texts = df_train['review_text'].values.tolist()\n",
        "n_train_texts = df_train['neutral_review_text'].values.tolist()\n",
        "f_train_texts = df_train['female_review_text'].values.tolist()\n",
        "m_train_texts = df_train['male_review_text'].values.tolist()\n",
        "train_labels = df_train['label'].values.tolist()\n",
        "\n",
        "test_texts = df_test['review_text'].values.tolist()\n",
        "n_test_texts = df_test['neutral_review_text'].values.tolist()\n",
        "f_test_texts = df_test['female_review_text'].values.tolist()\n",
        "m_test_texts = df_test['male_review_text'].values.tolist()\n",
        "test_labels = df_test['label'].values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dt-BL3PBAJW8"
      },
      "source": [
        "# Create dev set from portion of test set using split\n",
        "dev_texts, test_texts, _, _ = train_test_split(test_texts, test_labels, test_size=.5, random_state=seed)\n",
        "n_dev_texts, n_test_texts, _, _ = train_test_split(n_test_texts, test_labels, test_size=.5, random_state=seed)\n",
        "f_dev_texts, f_test_texts, _, _ = train_test_split(f_test_texts, test_labels, test_size=.5, random_state=seed)\n",
        "m_dev_texts, m_test_texts, dev_labels, test_labels = train_test_split(m_test_texts, test_labels, \n",
        "                                                                        test_size=.5, random_state=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQwDIzF2SOLK"
      },
      "source": [
        "#### TEST SMALL DATASETS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhPCDyapOfdO"
      },
      "source": [
        "# # TEST SMALL DATASETS\n",
        "# tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# small_train_encodings = tokenizer(train_texts[:1000], max_length=50, truncation=True, padding=True, return_tensors='tf')\n",
        "# small_dev_encodings = tokenizer(dev_texts[:1000], max_length=50, truncation=True, padding=True, return_tensors='tf')\n",
        "# small_test_encodings = tokenizer(test_texts[:1000], max_length=50, truncation=True, padding=True, return_tensors='tf')\n",
        "\n",
        "# small_train_labels = tf.convert_to_tensor(train_labels[:1000])\n",
        "# small_dev_labels = tf.convert_to_tensor(dev_labels[:1000])\n",
        "# small_test_labels = tf.convert_to_tensor(test_labels[:1000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deae2Cy-OA_c"
      },
      "source": [
        "# # TEST SMALL DATASETS\n",
        "# small_train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#     dict(small_train_encodings),\n",
        "#     small_train_labels\n",
        "# )).shuffle(1000, seed=seed).batch(8)\n",
        "\n",
        "# small_dev_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#     dict(small_dev_encodings),\n",
        "#     small_dev_labels\n",
        "# )).batch(8)\n",
        "\n",
        "# small_test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#     dict(small_test_encodings),\n",
        "#     small_test_labels\n",
        "# )).batch(8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrYkXYvVRLaZ"
      },
      "source": [
        "# # Initialize the TPU devices\n",
        "# if os.environ['COLAB_TPU_ADDR']:\n",
        "#   cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "#   tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "#   tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "#   tpu_strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "#   print('Using TPU')\n",
        "# elif tf.config.list_physical_devices('GPU'):\n",
        "#   strategy = tf.distribute.MirroredStrategy()\n",
        "#   print('Using GPU')\n",
        "# else:\n",
        "#   raise ValueError('Running on CPU is not recommended.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfR3rAGFPlk8"
      },
      "source": [
        "# with tpu_strategy.scope():\n",
        "#   small_model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
        "#   small_model.compile(\n",
        "#       optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
        "#       loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#       metrics=tf.metrics.SparseCategoricalAccuracy('accuracy'),\n",
        "#       ) \n",
        "#   small_model.fit(small_dev_dataset, validation_data=small_test_dataset, epochs=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G16z_9rHIWuj"
      },
      "source": [
        "### Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VVafMpfAJW8"
      },
      "source": [
        "# Specify tokenizer and batch encode original datasets\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, return_tensors='tf')\n",
        "dev_encodings = tokenizer(dev_texts, truncation=True, padding=True, return_tensors='tf')\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True, return_tensors='tf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgfwqs5i89wy"
      },
      "source": [
        "# Batch encode the neutral datasets\n",
        "\n",
        "n_train_encodings = tokenizer(n_train_texts, truncation=True, padding=True, return_tensors='tf')\n",
        "# n_dev_encodings = tokenizer(n_dev_texts, truncation=True, padding=True, return_tensors='tf')\n",
        "# n_test_encodings = tokenizer(n_test_texts, truncation=True, padding=True, return_tensors='tf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnUxrlUbYj4y"
      },
      "source": [
        "# Batch encode the male and female datasets\n",
        "\n",
        "# m_train_encodings = tokenizer(m_train_texts, truncation=True, padding=True, return_tensors='tf')\n",
        "# m_dev_encodings = tokenizer(m_dev_texts, truncation=True, padding=True, return_tensors='tf')\n",
        "m_test_encodings = tokenizer(m_test_texts, truncation=True, padding=True, return_tensors='tf')\n",
        "\n",
        "# f_train_encodings = tokenizer(f_train_texts, truncation=True, padding=True, return_tensors='tf')\n",
        "# f_dev_encodings = tokenizer(f_dev_texts, truncation=True, padding=True, return_tensors='tf')\n",
        "f_test_encodings = tokenizer(f_test_texts, truncation=True, padding=True, return_tensors='tf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJzS9noNItTs"
      },
      "source": [
        "### Create TF.Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnRvIbPMKFQ4"
      },
      "source": [
        "# Change labels list into tf.Tensors\n",
        "\n",
        "tf_train_labels = tf.convert_to_tensor(train_labels)\n",
        "tf_dev_labels = tf.convert_to_tensor(dev_labels)\n",
        "tf_test_labels = tf.convert_to_tensor(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXYKPoMoAJW8"
      },
      "source": [
        "# Turn original encodings into datasets for easy batching\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_encodings),\n",
        "    tf_train_labels\n",
        ")).shuffle(10000, seed=seed).batch(16)\n",
        "\n",
        "dev_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(dev_encodings),\n",
        "    tf_dev_labels\n",
        ")).batch(16)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(test_encodings),\n",
        "    tf_test_labels\n",
        ")).batch(16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ois9IdKx9MtH"
      },
      "source": [
        "# Turn neutral encodings into datasets for easy batching\n",
        "\n",
        "n_train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(n_train_encodings),\n",
        "    tf_train_labels\n",
        ")).shuffle(10000, seed=seed).batch(16)\n",
        "\n",
        "# n_dev_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#     dict(n_dev_encodings),\n",
        "#     tf_dev_labels\n",
        "# )).batch(16)\n",
        "\n",
        "# n_test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#     dict(n_test_encodings),\n",
        "#     tf_test_labels\n",
        "# )).batch(16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSa25jXQYj4y"
      },
      "source": [
        "# Turn male and female encodings into datasets for easy batching\n",
        "\n",
        "# m_train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#     dict(m_train_encodings),\n",
        "#     tf_train_labels\n",
        "# )).shuffle(10000, seed=seed).batch(16)\n",
        "\n",
        "# m_dev_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#     dict(m_dev_encodings),\n",
        "#     tf_dev_labels\n",
        "# )).batch(16)\n",
        "\n",
        "m_test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(m_test_encodings),\n",
        "    tf_test_labels\n",
        ")).batch(16)\n",
        "\n",
        "# f_train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#     dict(f_train_encodings),\n",
        "#     tf_train_labels\n",
        "# )).shuffle(10000, seed=seed).batch(16)\n",
        "\n",
        "# f_dev_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#     dict(f_dev_encodings),\n",
        "#     tf_dev_labels\n",
        "# )).batch(16)\n",
        "\n",
        "f_test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(f_test_encodings),\n",
        "    tf_test_labels\n",
        ")).batch(16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-EI4KcVI9V3"
      },
      "source": [
        "## Model Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLE5IM4cIzYl"
      },
      "source": [
        "### Initiliaze TF strategy (TPU preferred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbOfz02TYJJk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "00b52a98-b8e5-42f0-887d-d4bae9d86659"
      },
      "source": [
        "# Initialize the TPU devices\n",
        "if os.environ['COLAB_TPU_ADDR']:\n",
        "  cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "  tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "  strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "  print('Using TPU')\n",
        "elif tf.config.list_physical_devices('GPU'):\n",
        "  strategy = tf.distribute.MirroredStrategy()\n",
        "  print('Using GPU')\n",
        "else:\n",
        "  raise ValueError('Running on CPU is not recommended.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-1847c313b7e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Initialize the TPU devices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'COLAB_TPU_ADDR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mcluster_resolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPUClusterResolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_connect_to_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_tpu_system\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5mmdDBVJCDG"
      },
      "source": [
        "### Baseline Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B28YHNWE7lPJ"
      },
      "source": [
        "# Starter function to create the model (we can improve on this when we start using more complex models)\n",
        "def create_model():\n",
        "\n",
        "  return TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQYrxIhcJBYd"
      },
      "source": [
        "### Baseline Model v1 (5 epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHuIe8PoJMom"
      },
      "source": [
        "#### Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip8Ox5RiAjKn"
      },
      "source": [
        "# Create the model within each device scope\n",
        "models = []\n",
        "histories = []\n",
        "for train, dev in [(train_dataset, dev_dataset), (n_train_dataset, dev_dataset)]:\n",
        "  with strategy.scope():\n",
        "    model = create_model()\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
        "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n",
        "    \n",
        "  print(model.summary())\n",
        "\n",
        "  history = model.fit(train, validation_data=dev, epochs=5)\n",
        "    \n",
        "  histories.append(history)\n",
        "  models.append(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxur56ObJOfo"
      },
      "source": [
        "#### Test metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_7r-d2uV23L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9ea3807-d8df-4389-af1f-49c792f4f77e"
      },
      "source": [
        "# Evaluate the original baseline model\n",
        "models[0].evaluate(x=test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 7s 24ms/step - loss: 0.3141 - accuracy: 0.8793\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.31414440274238586, 0.8792732954025269]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOVB2K-dV5Rc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39c8e629-a225-49a6-f63d-cf0b66900935"
      },
      "source": [
        "# Evaluate the UNK baseline model\n",
        "models[1].evaluate(x=test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 7s 24ms/step - loss: 0.3795 - accuracy: 0.8716\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.37952134013175964, 0.8716232776641846]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJD8guuvJUuF"
      },
      "source": [
        "#### Sentiment "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLD8-4jTpcjY",
        "outputId": "68e372e7-fdb7-44bd-c92d-3760435d55c8"
      },
      "source": [
        "# Get the logits for both models on the male and female datasets respectively\n",
        "orig_m_logit_preds = models[0].predict(x=m_test_dataset).logits\n",
        "orig_f_logit_preds = models[0].predict(x=f_test_dataset).logits\n",
        "unk_m_logit_preds = models[1].predict(x=m_test_dataset).logits\n",
        "unk_f_logit_preds = models[1].predict(x=f_test_dataset).logits"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkrM8JRGvIOI",
        "outputId": "dd3b26b4-2f21-45af-ba25-91cb529bbd03"
      },
      "source": [
        "# Get the average sentiments for the original model\n",
        "m_pred_probs = tf.math.softmax(orig_m_logit_preds, axis=-1)\n",
        "f_pred_probs = tf.math.softmax(orig_f_logit_preds, axis=-1)\n",
        "\n",
        "print(\"Average Male Positive Sentiment:\", np.mean(m_pred_probs[:,1]))\n",
        "print(\"Average Female Positive Sentiment:\", np.mean(f_pred_probs[:,1]))\n",
        "print(\"Difference in Sentiment (Male - Female):\", np.mean(m_pred_probs[:,1])-np.mean(f_pred_probs[:,1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Male Positive Sentiment: 0.55594724\n",
            "Average Female Positive Sentiment: 0.5429732\n",
            "Difference in Sentiment (Male - Female): 0.012974024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk34chhgbC3B",
        "outputId": "04c6cf47-4ec9-415b-f8f2-5f1506ce1743"
      },
      "source": [
        "# Get the average sentiments for the unknown model\n",
        "m_pred_probs = tf.math.softmax(unk_m_logit_preds, axis=-1)\n",
        "f_pred_probs = tf.math.softmax(unk_f_logit_preds, axis=-1)\n",
        "\n",
        "print(\"Average Male Positive Sentiment:\", np.mean(m_pred_probs[:,1]))\n",
        "print(\"Average Female Positive Sentiment:\", np.mean(f_pred_probs[:,1]))\n",
        "print(\"Difference in Sentiment (Male - Female):\", np.mean(m_pred_probs[:,1])-np.mean(f_pred_probs[:,1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Male Positive Sentiment: 0.592404\n",
            "Average Female Positive Sentiment: 0.598442\n",
            "Difference in Sentiment (Male - Female): -0.00603801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDczF9ZmJZuM"
      },
      "source": [
        "#### Save models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46jT-IlMAJW9"
      },
      "source": [
        "# Save the models\n",
        "models[0].save_pretrained(CWD + \"/models/original_base_model_v1\")\n",
        "models[1].save_pretrained(CWD + \"/models/UNK_base_model_v1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqX1ETqxJcME"
      },
      "source": [
        "### Baseline Model v2 (10 epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYa_kUYhKDWt"
      },
      "source": [
        "#### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORLHTMn_wC0S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31372c32-c638-4ab5-c3b0-e45529ada58c"
      },
      "source": [
        "# Create the model within each device scope\n",
        "models1 = []\n",
        "histories1 = []\n",
        "for train, dev in [(train_dataset, dev_dataset), (n_train_dataset, dev_dataset)]:\n",
        "  with tpu_strategy.scope():\n",
        "    model = create_model()\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
        "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n",
        "    \n",
        "  print(model.summary())\n",
        "\n",
        "  history = model.fit(train, validation_data=dev, epochs=10)\n",
        "    \n",
        "  histories1.append(history)\n",
        "  models1.append(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['activation_13', 'vocab_projector', 'vocab_layer_norm', 'vocab_transform']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_39']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"tf_distil_bert_for_sequence_classification_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "distilbert (TFDistilBertMain multiple                  66362880  \n",
            "_________________________________________________________________\n",
            "pre_classifier (Dense)       multiple                  590592    \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  1538      \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         multiple                  0         \n",
            "=================================================================\n",
            "Total params: 66,955,010\n",
            "Trainable params: 66,955,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2092/2092 [==============================] - ETA: 0s - loss: 0.2943 - accuracy: 0.8727"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2092/2092 [==============================] - 198s 68ms/step - loss: 0.2943 - accuracy: 0.8727 - val_loss: 0.4985 - val_accuracy: 0.7724\n",
            "Epoch 2/10\n",
            "2092/2092 [==============================] - 135s 64ms/step - loss: 0.2086 - accuracy: 0.9182 - val_loss: 0.3427 - val_accuracy: 0.8511\n",
            "Epoch 3/10\n",
            "2092/2092 [==============================] - 136s 65ms/step - loss: 0.1939 - accuracy: 0.9288 - val_loss: 0.4342 - val_accuracy: 0.8346\n",
            "Epoch 4/10\n",
            "2092/2092 [==============================] - 136s 65ms/step - loss: 0.1397 - accuracy: 0.9510 - val_loss: 0.3076 - val_accuracy: 0.8757\n",
            "Epoch 5/10\n",
            "2092/2092 [==============================] - 136s 65ms/step - loss: 0.1090 - accuracy: 0.9635 - val_loss: 0.4383 - val_accuracy: 0.8776\n",
            "Epoch 6/10\n",
            "2092/2092 [==============================] - 135s 65ms/step - loss: 0.0923 - accuracy: 0.9697 - val_loss: 0.4310 - val_accuracy: 0.8699\n",
            "Epoch 7/10\n",
            "2092/2092 [==============================] - 135s 65ms/step - loss: 0.0738 - accuracy: 0.9781 - val_loss: 0.5764 - val_accuracy: 0.8460\n",
            "Epoch 8/10\n",
            "2092/2092 [==============================] - 135s 65ms/step - loss: 0.0543 - accuracy: 0.9834 - val_loss: 0.4403 - val_accuracy: 0.8812\n",
            "Epoch 9/10\n",
            "2092/2092 [==============================] - 137s 65ms/step - loss: 0.0661 - accuracy: 0.9794 - val_loss: 0.5837 - val_accuracy: 0.8652\n",
            "Epoch 10/10\n",
            "2092/2092 [==============================] - 135s 65ms/step - loss: 0.0364 - accuracy: 0.9903 - val_loss: 0.6469 - val_accuracy: 0.8699\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['activation_13', 'vocab_projector', 'vocab_layer_norm', 'vocab_transform']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_59']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"tf_distil_bert_for_sequence_classification_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "distilbert (TFDistilBertMain multiple                  66362880  \n",
            "_________________________________________________________________\n",
            "pre_classifier (Dense)       multiple                  590592    \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  1538      \n",
            "_________________________________________________________________\n",
            "dropout_59 (Dropout)         multiple                  0         \n",
            "=================================================================\n",
            "Total params: 66,955,010\n",
            "Trainable params: 66,955,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2092/2092 [==============================] - ETA: 0s - loss: 0.2669 - accuracy: 0.8870"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2092/2092 [==============================] - 193s 68ms/step - loss: 0.2669 - accuracy: 0.8870 - val_loss: 0.4584 - val_accuracy: 0.8183\n",
            "Epoch 2/10\n",
            "2092/2092 [==============================] - 135s 65ms/step - loss: 0.1962 - accuracy: 0.9252 - val_loss: 0.4989 - val_accuracy: 0.8104\n",
            "Epoch 3/10\n",
            "2092/2092 [==============================] - 136s 65ms/step - loss: 0.1346 - accuracy: 0.9513 - val_loss: 0.2991 - val_accuracy: 0.8841\n",
            "Epoch 4/10\n",
            "2092/2092 [==============================] - 136s 65ms/step - loss: 0.0967 - accuracy: 0.9684 - val_loss: 0.3567 - val_accuracy: 0.8757\n",
            "Epoch 5/10\n",
            "2092/2092 [==============================] - 136s 65ms/step - loss: 0.1403 - accuracy: 0.9476 - val_loss: 0.4715 - val_accuracy: 0.8723\n",
            "Epoch 6/10\n",
            "2092/2092 [==============================] - 136s 65ms/step - loss: 0.1077 - accuracy: 0.9650 - val_loss: 0.4227 - val_accuracy: 0.8716\n",
            "Epoch 7/10\n",
            "2092/2092 [==============================] - 137s 66ms/step - loss: 0.0823 - accuracy: 0.9747 - val_loss: 0.4151 - val_accuracy: 0.8527\n",
            "Epoch 8/10\n",
            "2092/2092 [==============================] - 136s 65ms/step - loss: 0.0714 - accuracy: 0.9779 - val_loss: 0.5524 - val_accuracy: 0.8484\n",
            "Epoch 9/10\n",
            "2092/2092 [==============================] - 137s 65ms/step - loss: 0.0658 - accuracy: 0.9791 - val_loss: 0.6066 - val_accuracy: 0.8633\n",
            "Epoch 10/10\n",
            "2092/2092 [==============================] - 135s 65ms/step - loss: 0.0545 - accuracy: 0.9848 - val_loss: 0.4836 - val_accuracy: 0.8774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e17A5xLgKMh3"
      },
      "source": [
        "#### Test metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lq3K-9jKMh3",
        "outputId": "4a94a333-bb28-4dfa-b05a-d32958bfc1a0"
      },
      "source": [
        "# Evaluate the original baseline model\n",
        "models1[0].evaluate(x=test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 8s 24ms/step - loss: 0.6274 - accuracy: 0.8743\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6274470686912537, 0.87425297498703]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Qr_16xBKMh4",
        "outputId": "35646f03-7960-466a-eb61-36f1d0081e07"
      },
      "source": [
        "# Evaluate the UNK baseline model\n",
        "models1[1].evaluate(x=test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 7s 24ms/step - loss: 0.4842 - accuracy: 0.8783\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4842031002044678, 0.8783169984817505]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw0SAR3ZZtKv"
      },
      "source": [
        "#### Sentiment "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h24YuYJZZtKv",
        "outputId": "dcd3dc2b-0bbc-4097-8546-a29164325a7f"
      },
      "source": [
        "# Get the logits for both models on the male and female datasets respectively\n",
        "orig_m_logit_preds = models1[0].predict(x=m_test_dataset).logits\n",
        "orig_f_logit_preds = models1[0].predict(x=f_test_dataset).logits\n",
        "unk_m_logit_preds = models1[1].predict(x=m_test_dataset).logits\n",
        "unk_f_logit_preds = models1[1].predict(x=f_test_dataset).logits"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M4A-vQAZtKv",
        "outputId": "fb55bdff-7ef4-4ff8-955a-2f8cf552e0e0"
      },
      "source": [
        "# Get the average sentiments for the original model\n",
        "m_pred_probs = tf.math.softmax(orig_m_logit_preds, axis=-1)\n",
        "f_pred_probs = tf.math.softmax(orig_f_logit_preds, axis=-1)\n",
        "\n",
        "print(\"Average Male Positive Sentiment:\", np.mean(m_pred_probs[:,1]))\n",
        "print(\"Average Female Positive Sentiment:\", np.mean(f_pred_probs[:,1]))\n",
        "print(\"Difference in Sentiment (Male - Female):\", np.mean(m_pred_probs[:,1])-np.mean(f_pred_probs[:,1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Male Positive Sentiment: 0.54753333\n",
            "Average Female Positive Sentiment: 0.53478456\n",
            "Difference in Sentiment (Male - Female): 0.012748778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cGLLIh1ZtKw",
        "outputId": "77141e24-089f-405c-c70f-182a699a80eb"
      },
      "source": [
        "# Get the average sentiments for the unknown model\n",
        "m_pred_probs = tf.math.softmax(unk_m_logit_preds, axis=-1)\n",
        "f_pred_probs = tf.math.softmax(unk_f_logit_preds, axis=-1)\n",
        "\n",
        "print(\"Average Male Positive Sentiment:\", np.mean(m_pred_probs[:,1]))\n",
        "print(\"Average Female Positive Sentiment:\", np.mean(f_pred_probs[:,1]))\n",
        "print(\"Difference in Sentiment (Male - Female):\", np.mean(m_pred_probs[:,1])-np.mean(f_pred_probs[:,1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Male Positive Sentiment: 0.531735\n",
            "Average Female Positive Sentiment: 0.535358\n",
            "Difference in Sentiment (Male - Female): -0.0036230087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh-nh9kRZtKw"
      },
      "source": [
        "#### Save models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RzEZnw4ZtKw"
      },
      "source": [
        "# Save the models\n",
        "models1[0].save_pretrained(CWD + \"/models/original_base_model_v2\")\n",
        "models1[1].save_pretrained(CWD + \"/models/UNK_base_model_v2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL-SZOsYZzVu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}