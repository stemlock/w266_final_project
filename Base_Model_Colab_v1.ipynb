{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Base_Model_Colab_v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stemlock/w266_final_project/blob/master/Base_Model_Colab_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C19pmdcHn3v"
      },
      "source": [
        "## Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TabsksoQAc_k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5842fa29-9709-4b07-8127-1bf2681e04af"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "CWD = '/content/drive/My Drive/W266 Final Project/Code'\n",
        "\n",
        "%cd $CWD"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/W266 Final Project/Code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTlSloE8FOKl"
      },
      "source": [
        "!pip install transformers==4.12.2\n",
        "!pip install tensorflow==2.5.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TlOLrfYAJWz"
      },
      "source": [
        "# Imports\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from transformers import DistilBertTokenizerFast, TFDistilBertForSequenceClassification, TFTrainer, TFTrainingArguments"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V70skwbn43oA",
        "outputId": "e37a43ff-f026-4b26-accc-329c6698e90b"
      },
      "source": [
        "print(\"Tensorflow version:\", tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version: 2.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMFmRBqF47eg"
      },
      "source": [
        "# print(\"Transformers version:\", transformers.__version__)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8-9RJ5FAJW1"
      },
      "source": [
        "# Set random seed\n",
        "seed = 42"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Frg-v4SIHtik"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7n1eWvPAJW3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "55e65001-1867-465e-81f1-9395f3bf3fd4"
      },
      "source": [
        "# Read in processed data (Rows with NA in the neutral_review_text had no tokens replaced)\n",
        "df_train = pd.read_csv('data/model_train.csv')\n",
        "df_test = pd.read_csv('data/model_test.csv')\n",
        "df_train.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review_score</th>\n",
              "      <th>review_text</th>\n",
              "      <th>neutral_review_text</th>\n",
              "      <th>neutral_sub_count</th>\n",
              "      <th>female_review_text</th>\n",
              "      <th>female_sub_count</th>\n",
              "      <th>male_review_text</th>\n",
              "      <th>male_sub_count</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6990</td>\n",
              "      <td>1</td>\n",
              "      <td>What the hell is this? Its one of the dumbest ...</td>\n",
              "      <td>what the hell is this? its one of the dumbest ...</td>\n",
              "      <td>1</td>\n",
              "      <td>what the hell is this? its one of the dumbest ...</td>\n",
              "      <td>1</td>\n",
              "      <td>what the hell is this? its one of the dumbest ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12145</td>\n",
              "      <td>1</td>\n",
              "      <td>As you may have gathered from the title, I who...</td>\n",
              "      <td>as you may have gathered from the title, i who...</td>\n",
              "      <td>8</td>\n",
              "      <td>as you may have gathered from the title, i who...</td>\n",
              "      <td>7</td>\n",
              "      <td>as you may have gathered from the title, i who...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7457</td>\n",
              "      <td>1</td>\n",
              "      <td>This Canadian \"movie\" is the worst ever! Stunn...</td>\n",
              "      <td>this canadian \"movie\" is the worst ever! stunn...</td>\n",
              "      <td>7</td>\n",
              "      <td>this canadian \"movie\" is the worst ever! stunn...</td>\n",
              "      <td>5</td>\n",
              "      <td>this canadian \"movie\" is the worst ever! stunn...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7324</td>\n",
              "      <td>1</td>\n",
              "      <td>Being a Film studies graduate I would like to ...</td>\n",
              "      <td>being a film studies graduate i would like to ...</td>\n",
              "      <td>2</td>\n",
              "      <td>being a film studies graduate i would like to ...</td>\n",
              "      <td>1</td>\n",
              "      <td>being a film studies graduate i would like to ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7089</td>\n",
              "      <td>1</td>\n",
              "      <td>A sexually obsessed chef leads a duplicitous l...</td>\n",
              "      <td>a sexually obsessed chef leads a duplicitous l...</td>\n",
              "      <td>7</td>\n",
              "      <td>a sexually obsessed chef leads a duplicitous l...</td>\n",
              "      <td>4</td>\n",
              "      <td>a sexually obsessed chef leads a duplicitous l...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   review_id  review_score  ... male_sub_count label\n",
              "0       6990             1  ...              0     0\n",
              "1      12145             1  ...              1     0\n",
              "2       7457             1  ...              2     0\n",
              "3       7324             1  ...              1     0\n",
              "4       7089             1  ...              3     0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjJKICtbHyaG"
      },
      "source": [
        "## Baseline Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kzs4ALv_H6aw"
      },
      "source": [
        "### Majority tokens average"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV2kQwfshkCu"
      },
      "source": [
        "# Extract the male vs female majority texts\n",
        "df_female_majority = df_test[df_test['male_sub_count'] > df_test['female_sub_count']]\n",
        "df_male_majority = df_test[df_test['male_sub_count'] < df_test['female_sub_count']]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnLOai5MiFGK",
        "outputId": "23ef32d3-360b-40e0-8980-4365300a36b7"
      },
      "source": [
        "# Average sentiment for female majority texts\n",
        "print(\"Average female review binary sentiment:\", df_female_majority['label'].mean())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average female review binary sentiment: 0.4896039603960396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VevUcJ8njWby",
        "outputId": "0918e050-143a-45f8-d5be-1199db2b66d6"
      },
      "source": [
        "# Average review score for female majority texts\n",
        "print(\"Average female review score 1-10:\", df_female_majority['review_score'].mean())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average female review score 1-10: 5.436138613861386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtS6FogMiSiI",
        "outputId": "d6f8b8be-19d7-4448-a128-6646cf4659a2"
      },
      "source": [
        "# Average sentiment for male majority texts\n",
        "print(\"Average male review binary sentiment:\", df_male_majority['label'].mean())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average male review binary sentiment: 0.5035229420862691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLXTizgqjnni",
        "outputId": "9ccd36b2-63fc-4171-ec8c-1f201f2aa0f5"
      },
      "source": [
        "# Average review score for male majority texts\n",
        "print(\"Average male review score 1-10:\", df_male_majority['review_score'].mean())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average male review score 1-10: 5.509709572091425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTrnQ2GbkTTc",
        "outputId": "0e24b99a-b2f9-4c60-8ecd-cc2d85009722"
      },
      "source": [
        "# Distribution of scores across review scores for female majority texts\n",
        "df_female_majority['review_score'].value_counts()/len(df_female_majority)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     0.181683\n",
              "10    0.171782\n",
              "8     0.121287\n",
              "4     0.121287\n",
              "3     0.111386\n",
              "7     0.106931\n",
              "2     0.096040\n",
              "9     0.089604\n",
              "Name: review_score, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vM8jKJ2kKHc",
        "outputId": "23a8e364-1f93-4448-f687-cb1d57dc8e93"
      },
      "source": [
        "# Distribution of scores across review scores for male majority texts\n",
        "df_male_majority['review_score'].value_counts()/len(df_male_majority)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     0.197457\n",
              "10    0.190067\n",
              "8     0.120124\n",
              "4     0.105860\n",
              "3     0.101564\n",
              "7     0.100361\n",
              "9     0.092971\n",
              "2     0.091596\n",
              "Name: review_score, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmzVoXGVIATU"
      },
      "source": [
        "### Proportional weighted average"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMdjzwMInAT3"
      },
      "source": [
        "# Extract the proportion of male vs female tokens per review\n",
        "male_proportion = (df_test['female_sub_count']/df_test['neutral_sub_count'])\n",
        "female_proportion = (df_test['male_sub_count']/df_test['neutral_sub_count'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KWiEVdrnFJ_",
        "outputId": "0b08df47-e991-4b2f-e585-8663f093c09e"
      },
      "source": [
        "# Weighted average sentiment for female tokens\n",
        "(df_test['label']*female_proportion).sum()/female_proportion.sum()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4922782109404571"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZUcV1WGnJQO",
        "outputId": "a41776c3-89a1-42dc-b8ca-76de7526d9ef"
      },
      "source": [
        "# Weighted average review scores for female tokens\n",
        "(df_test['review_score']*female_proportion).sum()/female_proportion.sum()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.440864712868192"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHD9eRnCoNwx",
        "outputId": "63cd6ff5-f256-4803-935b-791e704f74e1"
      },
      "source": [
        "# Weighted average sentiment for male tokens\n",
        "(df_test['label']*male_proportion).sum()/male_proportion.sum()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5028605798629667"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NSn2Y88kkP7",
        "outputId": "5a8737b1-4402-407e-9dab-8ce7ed737ca3"
      },
      "source": [
        "# Weighted average review scores for male tokens\n",
        "(df_test['review_score']*male_proportion).sum()/male_proportion.sum()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.508159425039407"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4swCd7jIESR"
      },
      "source": [
        "## Data Transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I9lXGmQyN4T"
      },
      "source": [
        "# ## TO DO: Try to fix this function. For some reason, this causes the model.fit() to fail\n",
        "# def encode_datasets(X_train, y_train, X_test, y_test, tokenizer, split_size=0.5, seed=42):\n",
        "\n",
        "#   '''\n",
        "#   Takes in train and test data and encodes them into train, dev, and test\n",
        "#   TF datasets using the provided tokenizer.\n",
        "#   '''\n",
        "\n",
        "#   # Split test set into dev and test\n",
        "#   X_dev, X_test, y_dev, y_test = train_test_split(X_test, y_test, test_size=split_size, random_state=seed)\n",
        "\n",
        "#   # Apply tokenizer to each dataset\n",
        "#   train_encodings = tokenizer(X_train, truncation=True, padding=True)\n",
        "#   dev_encodings = tokenizer(X_dev, truncation=True, padding=True)\n",
        "#   test_encodings = tokenizer(X_test, truncation=True, padding=True)\n",
        "\n",
        "#   # Turn encodings into datasets for easy batching\n",
        "#   train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#       dict(train_encodings),\n",
        "#       y_train\n",
        "#   ))\n",
        "#   dev_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#       dict(dev_encodings),\n",
        "#       y_dev\n",
        "#   ))\n",
        "#   test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#       dict(test_encodings),\n",
        "#       y_test\n",
        "#   ))\n",
        "\n",
        "#   return train_dataset, dev_dataset, test_dataset"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU9Qx8R5-NjG"
      },
      "source": [
        "# # Load data\n",
        "# train_texts = df_train['review_text'].values.tolist()\n",
        "# n_train_texts = df_train['neutral_review_text'].values.tolist()\n",
        "# f_train_texts = df_train['female_review_text'].values.tolist()\n",
        "# m_train_texts = df_train['male_review_text'].values.tolist()\n",
        "# train_labels = df_train['label'].values.tolist()\n",
        "\n",
        "# test_texts = df_test['review_text'].values.tolist()\n",
        "# n_test_texts = df_test['neutral_review_text'].values.tolist()\n",
        "# f_test_texts = df_test['female_review_text'].values.tolist()\n",
        "# m_test_texts = df_test['male_review_text'].values.tolist()\n",
        "# test_labels = df_test['label'].values.tolist()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHS5FQKcz2Th"
      },
      "source": [
        "# # Specify tokenizer and encode each dataset\n",
        "# tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# train_dataset, dev_dataset, test_dataset = encode_datasets(train_texts, train_labels, \n",
        "#                                                            test_texts, test_labels,\n",
        "#                                                            tokenizer)\n",
        "# n_train_dataset, n_dev_dataset, n_test_dataset = encode_datasets(n_train_texts, train_labels, \n",
        "#                                                                  n_test_texts, test_labels,\n",
        "#                                                                  tokenizer)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nR2fsZXK3m7"
      },
      "source": [
        "### Split data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8i696DrAJW7"
      },
      "source": [
        "# Load data\n",
        "train_texts = df_train['review_text'].values.tolist()\n",
        "n_train_texts = df_train['neutral_review_text'].values.tolist()\n",
        "f_train_texts = df_train['female_review_text'].values.tolist()\n",
        "m_train_texts = df_train['male_review_text'].values.tolist()\n",
        "train_labels = df_train['label'].values.tolist()\n",
        "\n",
        "test_texts = df_test['review_text'].values.tolist()\n",
        "n_test_texts = df_test['neutral_review_text'].values.tolist()\n",
        "f_test_texts = df_test['female_review_text'].values.tolist()\n",
        "m_test_texts = df_test['male_review_text'].values.tolist()\n",
        "test_labels = df_test['label'].values.tolist()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dt-BL3PBAJW8"
      },
      "source": [
        "# Create dev set from portion of test set using split\n",
        "dev_texts, test_texts, _, _ = train_test_split(test_texts, test_labels, test_size=.5, random_state=seed)\n",
        "n_dev_texts, n_test_texts, _, _ = train_test_split(n_test_texts, test_labels, test_size=.5, random_state=seed)\n",
        "f_dev_texts, f_test_texts, _, _ = train_test_split(f_test_texts, test_labels, test_size=.5, random_state=seed)\n",
        "m_dev_texts, m_test_texts, dev_labels, test_labels = train_test_split(m_test_texts, test_labels, \n",
        "                                                                        test_size=.5, random_state=seed)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQwDIzF2SOLK"
      },
      "source": [
        "#### TEST SMALL DATASETS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhPCDyapOfdO"
      },
      "source": [
        "# # TEST SMALL DATASETS\n",
        "# tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# small_train_encodings = tokenizer(train_texts[:1000], max_length=50, truncation=True, padding=True, return_tensors='tf')\n",
        "# small_dev_encodings = tokenizer(dev_texts[:1000], max_length=50, truncation=True, padding=True, return_tensors='tf')\n",
        "# small_test_encodings = tokenizer(test_texts[:1000], max_length=50, truncation=True, padding=True, return_tensors='tf')\n",
        "\n",
        "# small_train_labels = tf.convert_to_tensor(train_labels[:1000])\n",
        "# small_dev_labels = tf.convert_to_tensor(dev_labels[:1000])\n",
        "# small_test_labels = tf.convert_to_tensor(test_labels[:1000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deae2Cy-OA_c"
      },
      "source": [
        "# # TEST SMALL DATASETS\n",
        "# small_train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#     dict(small_train_encodings),\n",
        "#     small_train_labels\n",
        "# )).shuffle(1000, seed=seed).batch(8)\n",
        "\n",
        "# small_dev_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#     dict(small_dev_encodings),\n",
        "#     small_dev_labels\n",
        "# )).batch(8)\n",
        "\n",
        "# small_test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#     dict(small_test_encodings),\n",
        "#     small_test_labels\n",
        "# )).batch(8)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrYkXYvVRLaZ"
      },
      "source": [
        "# # Initialize the TPU devices\n",
        "# if os.environ['COLAB_TPU_ADDR']:\n",
        "#   cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "#   tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "#   tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "#   tpu_strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "#   print('Using TPU')\n",
        "# elif tf.config.list_physical_devices('GPU'):\n",
        "#   strategy = tf.distribute.MirroredStrategy()\n",
        "#   print('Using GPU')\n",
        "# else:\n",
        "#   raise ValueError('Running on CPU is not recommended.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfR3rAGFPlk8"
      },
      "source": [
        "# with tpu_strategy.scope():\n",
        "#   small_model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
        "#   small_model.compile(\n",
        "#       optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
        "#       loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#       metrics=tf.metrics.SparseCategoricalAccuracy('accuracy'),\n",
        "#       ) \n",
        "#   small_model.fit(small_dev_dataset, validation_data=small_test_dataset, epochs=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G16z_9rHIWuj"
      },
      "source": [
        "### Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VVafMpfAJW8"
      },
      "source": [
        "# Specify tokenizer and batch encode original datasets\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, return_tensors='tf')\n",
        "dev_encodings = tokenizer(dev_texts, truncation=True, padding=True, return_tensors='tf')\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True, return_tensors='tf')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgfwqs5i89wy"
      },
      "source": [
        "# Batch encode the neutral datasets\n",
        "\n",
        "n_train_encodings = tokenizer(n_train_texts, truncation=True, padding=True, return_tensors='tf')\n",
        "# n_dev_encodings = tokenizer(n_dev_texts, truncation=True, padding=True, return_tensors='tf')\n",
        "# n_test_encodings = tokenizer(n_test_texts, truncation=True, padding=True, return_tensors='tf')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnUxrlUbYj4y"
      },
      "source": [
        "# Batch encode the male and female datasets\n",
        "\n",
        "# m_train_encodings = tokenizer(m_train_texts, truncation=True, padding=True, return_tensors='tf')\n",
        "# m_dev_encodings = tokenizer(m_dev_texts, truncation=True, padding=True, return_tensors='tf')\n",
        "m_test_encodings = tokenizer(m_test_texts, truncation=True, padding=True, return_tensors='tf')\n",
        "\n",
        "# f_train_encodings = tokenizer(f_train_texts, truncation=True, padding=True, return_tensors='tf')\n",
        "# f_dev_encodings = tokenizer(f_dev_texts, truncation=True, padding=True, return_tensors='tf')\n",
        "f_test_encodings = tokenizer(f_test_texts, truncation=True, padding=True, return_tensors='tf')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJzS9noNItTs"
      },
      "source": [
        "### Create TF.Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnRvIbPMKFQ4"
      },
      "source": [
        "# Change labels list into tf.Tensors\n",
        "\n",
        "tf_train_labels = tf.convert_to_tensor(train_labels)\n",
        "tf_dev_labels = tf.convert_to_tensor(dev_labels)\n",
        "tf_test_labels = tf.convert_to_tensor(test_labels)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXYKPoMoAJW8"
      },
      "source": [
        "# Turn original encodings into datasets for easy batching\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_encodings),\n",
        "    tf_train_labels\n",
        ")).shuffle(10000, seed=seed).batch(16)\n",
        "\n",
        "dev_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(dev_encodings),\n",
        "    tf_dev_labels\n",
        ")).batch(16)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(test_encodings),\n",
        "    tf_test_labels\n",
        ")).batch(16)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ois9IdKx9MtH"
      },
      "source": [
        "# Turn neutral encodings into datasets for easy batching\n",
        "\n",
        "n_train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(n_train_encodings),\n",
        "    tf_train_labels\n",
        ")).shuffle(10000, seed=seed).batch(16)\n",
        "\n",
        "# n_dev_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#     dict(n_dev_encodings),\n",
        "#     tf_dev_labels\n",
        "# )).batch(16)\n",
        "\n",
        "# n_test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#     dict(n_test_encodings),\n",
        "#     tf_test_labels\n",
        "# )).batch(16)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSa25jXQYj4y"
      },
      "source": [
        "# Turn male and female encodings into datasets for easy batching\n",
        "\n",
        "# m_train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#     dict(m_train_encodings),\n",
        "#     tf_train_labels\n",
        "# )).shuffle(10000, seed=seed).batch(16)\n",
        "\n",
        "# m_dev_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#     dict(m_dev_encodings),\n",
        "#     tf_dev_labels\n",
        "# )).batch(16)\n",
        "\n",
        "m_test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(m_test_encodings),\n",
        "    tf_test_labels\n",
        ")).batch(16)\n",
        "\n",
        "# f_train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#     dict(f_train_encodings),\n",
        "#     tf_train_labels\n",
        "# )).shuffle(10000, seed=seed).batch(16)\n",
        "\n",
        "# f_dev_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#     dict(f_dev_encodings),\n",
        "#     tf_dev_labels\n",
        "# )).batch(16)\n",
        "\n",
        "f_test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(f_test_encodings),\n",
        "    tf_test_labels\n",
        ")).batch(16)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-EI4KcVI9V3"
      },
      "source": [
        "## Model Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLE5IM4cIzYl"
      },
      "source": [
        "### Initiliaze TF strategy (TPU preferred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbOfz02TYJJk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84a11314-09ce-4792-94c5-53b58172ea32"
      },
      "source": [
        "# Initialize the TPU devices\n",
        "if os.environ['COLAB_TPU_ADDR']:\n",
        "  cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "  tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "  tpu_strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "  print('Using TPU')\n",
        "elif tf.config.list_physical_devices('GPU'):\n",
        "  strategy = tf.distribute.MirroredStrategy()\n",
        "  print('Using GPU')\n",
        "else:\n",
        "  raise ValueError('Running on CPU is not recommended.')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.18.253.90:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.18.253.90:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.18.253.90:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.18.253.90:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5mmdDBVJCDG"
      },
      "source": [
        "### Baseline Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B28YHNWE7lPJ"
      },
      "source": [
        "# Starter function to create the model (we can improve on this when we start using more complex models)\n",
        "def create_model():\n",
        "\n",
        "  return TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQYrxIhcJBYd"
      },
      "source": [
        "### Baseline Model v1 (5 epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHuIe8PoJMom"
      },
      "source": [
        "#### Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip8Ox5RiAjKn"
      },
      "source": [
        "# Create the model within each device scope\n",
        "models = []\n",
        "histories = []\n",
        "for train, dev in [(train_dataset, dev_dataset), (n_train_dataset, dev_dataset)]:\n",
        "  with tpu_strategy.scope():\n",
        "    model = create_model()\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
        "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n",
        "    \n",
        "  print(model.summary())\n",
        "\n",
        "  history = model.fit(train, validation_data=dev, epochs=5)\n",
        "    \n",
        "  histories.append(history)\n",
        "  models.append(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxur56ObJOfo"
      },
      "source": [
        "#### Test metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_7r-d2uV23L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9ea3807-d8df-4389-af1f-49c792f4f77e"
      },
      "source": [
        "# Evaluate the original baseline model\n",
        "models[0].evaluate(x=test_dataset)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 7s 24ms/step - loss: 0.3141 - accuracy: 0.8793\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.31414440274238586, 0.8792732954025269]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOVB2K-dV5Rc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39c8e629-a225-49a6-f63d-cf0b66900935"
      },
      "source": [
        "# Evaluate the UNK baseline model\n",
        "models[1].evaluate(x=test_dataset)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 7s 24ms/step - loss: 0.3795 - accuracy: 0.8716\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.37952134013175964, 0.8716232776641846]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJD8guuvJUuF"
      },
      "source": [
        "#### Sentiment "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLD8-4jTpcjY",
        "outputId": "68e372e7-fdb7-44bd-c92d-3760435d55c8"
      },
      "source": [
        "# Get the logits for both models on the male and female datasets respectively\n",
        "orig_m_logit_preds = models[0].predict(x=m_test_dataset).logits\n",
        "orig_f_logit_preds = models[0].predict(x=f_test_dataset).logits\n",
        "unk_m_logit_preds = models[1].predict(x=m_test_dataset).logits\n",
        "unk_f_logit_preds = models[1].predict(x=f_test_dataset).logits"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkrM8JRGvIOI",
        "outputId": "dd3b26b4-2f21-45af-ba25-91cb529bbd03"
      },
      "source": [
        "# Get the average sentiments for the original model\n",
        "m_pred_probs = tf.math.softmax(orig_m_logit_preds, axis=-1)\n",
        "f_pred_probs = tf.math.softmax(orig_f_logit_preds, axis=-1)\n",
        "\n",
        "print(\"Average Male Positive Sentiment:\", np.mean(m_pred_probs[:,1]))\n",
        "print(\"Average Female Positive Sentiment:\", np.mean(f_pred_probs[:,1]))\n",
        "print(\"Difference in Sentiment (Male - Female):\", np.mean(m_pred_probs[:,1])-np.mean(f_pred_probs[:,1]))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Male Positive Sentiment: 0.55594724\n",
            "Average Female Positive Sentiment: 0.5429732\n",
            "Difference in Sentiment (Male - Female): 0.012974024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk34chhgbC3B",
        "outputId": "04c6cf47-4ec9-415b-f8f2-5f1506ce1743"
      },
      "source": [
        "# Get the average sentiments for the unknown model\n",
        "m_pred_probs = tf.math.softmax(unk_m_logit_preds, axis=-1)\n",
        "f_pred_probs = tf.math.softmax(unk_f_logit_preds, axis=-1)\n",
        "\n",
        "print(\"Average Male Positive Sentiment:\", np.mean(m_pred_probs[:,1]))\n",
        "print(\"Average Female Positive Sentiment:\", np.mean(f_pred_probs[:,1]))\n",
        "print(\"Difference in Sentiment (Male - Female):\", np.mean(m_pred_probs[:,1])-np.mean(f_pred_probs[:,1]))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Male Positive Sentiment: 0.592404\n",
            "Average Female Positive Sentiment: 0.598442\n",
            "Difference in Sentiment (Male - Female): -0.00603801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDczF9ZmJZuM"
      },
      "source": [
        "#### Save models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46jT-IlMAJW9"
      },
      "source": [
        "# Save the models\n",
        "models[0].save_pretrained(CWD + \"/models/original_base_model_v1\")\n",
        "models[1].save_pretrained(CWD + \"/models/UNK_base_model_v1\")"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqX1ETqxJcME"
      },
      "source": [
        "### Baseline Model v2 (10 epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYa_kUYhKDWt"
      },
      "source": [
        "#### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORLHTMn_wC0S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31372c32-c638-4ab5-c3b0-e45529ada58c"
      },
      "source": [
        "# Create the model within each device scope\n",
        "models1 = []\n",
        "histories1 = []\n",
        "for train, dev in [(train_dataset, dev_dataset), (n_train_dataset, dev_dataset)]:\n",
        "  with tpu_strategy.scope():\n",
        "    model = create_model()\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
        "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n",
        "    \n",
        "  print(model.summary())\n",
        "\n",
        "  history = model.fit(train, validation_data=dev, epochs=10)\n",
        "    \n",
        "  histories1.append(history)\n",
        "  models1.append(model)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['activation_13', 'vocab_projector', 'vocab_layer_norm', 'vocab_transform']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_39']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"tf_distil_bert_for_sequence_classification_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "distilbert (TFDistilBertMain multiple                  66362880  \n",
            "_________________________________________________________________\n",
            "pre_classifier (Dense)       multiple                  590592    \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  1538      \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         multiple                  0         \n",
            "=================================================================\n",
            "Total params: 66,955,010\n",
            "Trainable params: 66,955,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2092/2092 [==============================] - ETA: 0s - loss: 0.2943 - accuracy: 0.8727"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2092/2092 [==============================] - 198s 68ms/step - loss: 0.2943 - accuracy: 0.8727 - val_loss: 0.4985 - val_accuracy: 0.7724\n",
            "Epoch 2/10\n",
            "2092/2092 [==============================] - 135s 64ms/step - loss: 0.2086 - accuracy: 0.9182 - val_loss: 0.3427 - val_accuracy: 0.8511\n",
            "Epoch 3/10\n",
            "2092/2092 [==============================] - 136s 65ms/step - loss: 0.1939 - accuracy: 0.9288 - val_loss: 0.4342 - val_accuracy: 0.8346\n",
            "Epoch 4/10\n",
            "2092/2092 [==============================] - 136s 65ms/step - loss: 0.1397 - accuracy: 0.9510 - val_loss: 0.3076 - val_accuracy: 0.8757\n",
            "Epoch 5/10\n",
            "2092/2092 [==============================] - 136s 65ms/step - loss: 0.1090 - accuracy: 0.9635 - val_loss: 0.4383 - val_accuracy: 0.8776\n",
            "Epoch 6/10\n",
            "2092/2092 [==============================] - 135s 65ms/step - loss: 0.0923 - accuracy: 0.9697 - val_loss: 0.4310 - val_accuracy: 0.8699\n",
            "Epoch 7/10\n",
            "2092/2092 [==============================] - 135s 65ms/step - loss: 0.0738 - accuracy: 0.9781 - val_loss: 0.5764 - val_accuracy: 0.8460\n",
            "Epoch 8/10\n",
            "2092/2092 [==============================] - 135s 65ms/step - loss: 0.0543 - accuracy: 0.9834 - val_loss: 0.4403 - val_accuracy: 0.8812\n",
            "Epoch 9/10\n",
            "2092/2092 [==============================] - 137s 65ms/step - loss: 0.0661 - accuracy: 0.9794 - val_loss: 0.5837 - val_accuracy: 0.8652\n",
            "Epoch 10/10\n",
            "2092/2092 [==============================] - 135s 65ms/step - loss: 0.0364 - accuracy: 0.9903 - val_loss: 0.6469 - val_accuracy: 0.8699\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['activation_13', 'vocab_projector', 'vocab_layer_norm', 'vocab_transform']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_59']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"tf_distil_bert_for_sequence_classification_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "distilbert (TFDistilBertMain multiple                  66362880  \n",
            "_________________________________________________________________\n",
            "pre_classifier (Dense)       multiple                  590592    \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  1538      \n",
            "_________________________________________________________________\n",
            "dropout_59 (Dropout)         multiple                  0         \n",
            "=================================================================\n",
            "Total params: 66,955,010\n",
            "Trainable params: 66,955,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2092/2092 [==============================] - ETA: 0s - loss: 0.2669 - accuracy: 0.8870"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2092/2092 [==============================] - 193s 68ms/step - loss: 0.2669 - accuracy: 0.8870 - val_loss: 0.4584 - val_accuracy: 0.8183\n",
            "Epoch 2/10\n",
            "2092/2092 [==============================] - 135s 65ms/step - loss: 0.1962 - accuracy: 0.9252 - val_loss: 0.4989 - val_accuracy: 0.8104\n",
            "Epoch 3/10\n",
            "2092/2092 [==============================] - 136s 65ms/step - loss: 0.1346 - accuracy: 0.9513 - val_loss: 0.2991 - val_accuracy: 0.8841\n",
            "Epoch 4/10\n",
            "2092/2092 [==============================] - 136s 65ms/step - loss: 0.0967 - accuracy: 0.9684 - val_loss: 0.3567 - val_accuracy: 0.8757\n",
            "Epoch 5/10\n",
            "2092/2092 [==============================] - 136s 65ms/step - loss: 0.1403 - accuracy: 0.9476 - val_loss: 0.4715 - val_accuracy: 0.8723\n",
            "Epoch 6/10\n",
            "2092/2092 [==============================] - 136s 65ms/step - loss: 0.1077 - accuracy: 0.9650 - val_loss: 0.4227 - val_accuracy: 0.8716\n",
            "Epoch 7/10\n",
            "2092/2092 [==============================] - 137s 66ms/step - loss: 0.0823 - accuracy: 0.9747 - val_loss: 0.4151 - val_accuracy: 0.8527\n",
            "Epoch 8/10\n",
            "2092/2092 [==============================] - 136s 65ms/step - loss: 0.0714 - accuracy: 0.9779 - val_loss: 0.5524 - val_accuracy: 0.8484\n",
            "Epoch 9/10\n",
            "2092/2092 [==============================] - 137s 65ms/step - loss: 0.0658 - accuracy: 0.9791 - val_loss: 0.6066 - val_accuracy: 0.8633\n",
            "Epoch 10/10\n",
            "2092/2092 [==============================] - 135s 65ms/step - loss: 0.0545 - accuracy: 0.9848 - val_loss: 0.4836 - val_accuracy: 0.8774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e17A5xLgKMh3"
      },
      "source": [
        "#### Test metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lq3K-9jKMh3",
        "outputId": "4a94a333-bb28-4dfa-b05a-d32958bfc1a0"
      },
      "source": [
        "# Evaluate the original baseline model\n",
        "models1[0].evaluate(x=test_dataset)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 8s 24ms/step - loss: 0.6274 - accuracy: 0.8743\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6274470686912537, 0.87425297498703]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Qr_16xBKMh4",
        "outputId": "35646f03-7960-466a-eb61-36f1d0081e07"
      },
      "source": [
        "# Evaluate the UNK baseline model\n",
        "models1[1].evaluate(x=test_dataset)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 7s 24ms/step - loss: 0.4842 - accuracy: 0.8783\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4842031002044678, 0.8783169984817505]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw0SAR3ZZtKv"
      },
      "source": [
        "#### Sentiment "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h24YuYJZZtKv",
        "outputId": "dcd3dc2b-0bbc-4097-8546-a29164325a7f"
      },
      "source": [
        "# Get the logits for both models on the male and female datasets respectively\n",
        "orig_m_logit_preds = models1[0].predict(x=m_test_dataset).logits\n",
        "orig_f_logit_preds = models1[0].predict(x=f_test_dataset).logits\n",
        "unk_m_logit_preds = models1[1].predict(x=m_test_dataset).logits\n",
        "unk_f_logit_preds = models1[1].predict(x=f_test_dataset).logits"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M4A-vQAZtKv",
        "outputId": "fb55bdff-7ef4-4ff8-955a-2f8cf552e0e0"
      },
      "source": [
        "# Get the average sentiments for the original model\n",
        "m_pred_probs = tf.math.softmax(orig_m_logit_preds, axis=-1)\n",
        "f_pred_probs = tf.math.softmax(orig_f_logit_preds, axis=-1)\n",
        "\n",
        "print(\"Average Male Positive Sentiment:\", np.mean(m_pred_probs[:,1]))\n",
        "print(\"Average Female Positive Sentiment:\", np.mean(f_pred_probs[:,1]))\n",
        "print(\"Difference in Sentiment (Male - Female):\", np.mean(m_pred_probs[:,1])-np.mean(f_pred_probs[:,1]))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Male Positive Sentiment: 0.54753333\n",
            "Average Female Positive Sentiment: 0.53478456\n",
            "Difference in Sentiment (Male - Female): 0.012748778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cGLLIh1ZtKw",
        "outputId": "77141e24-089f-405c-c70f-182a699a80eb"
      },
      "source": [
        "# Get the average sentiments for the unknown model\n",
        "m_pred_probs = tf.math.softmax(unk_m_logit_preds, axis=-1)\n",
        "f_pred_probs = tf.math.softmax(unk_f_logit_preds, axis=-1)\n",
        "\n",
        "print(\"Average Male Positive Sentiment:\", np.mean(m_pred_probs[:,1]))\n",
        "print(\"Average Female Positive Sentiment:\", np.mean(f_pred_probs[:,1]))\n",
        "print(\"Difference in Sentiment (Male - Female):\", np.mean(m_pred_probs[:,1])-np.mean(f_pred_probs[:,1]))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Male Positive Sentiment: 0.531735\n",
            "Average Female Positive Sentiment: 0.535358\n",
            "Difference in Sentiment (Male - Female): -0.0036230087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh-nh9kRZtKw"
      },
      "source": [
        "#### Save models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RzEZnw4ZtKw"
      },
      "source": [
        "# Save the models\n",
        "models1[0].save_pretrained(CWD + \"/models/original_base_model_v2\")\n",
        "models1[1].save_pretrained(CWD + \"/models/UNK_base_model_v2\")"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL-SZOsYZzVu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}